{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train = pd.read_csv(r'C:\\Users\\Home\\Downloads\\fashion-mnist\\fashion-mnist_train.csv')\n",
    "data_test = pd.read_csv(r'C:\\Users\\Home\\Downloads\\fashion-mnist\\fashion-mnist_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "X = np.array(data_train.iloc[:, 1:])\n",
    "y = to_categorical(np.array(data_train.iloc[:, 0]))\n",
    "\n",
    "#Here we split validation data to optimiza classifier during training\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=13)\n",
    "\n",
    "#Test data\n",
    "X_test = np.array(data_test.iloc[:, 1:])\n",
    "y_test = to_categorical(np.array(data_test.iloc[:, 0]))\n",
    "\n",
    "\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n",
    "X_val = X_val.reshape(X_val.shape[0], img_rows, img_cols, 1)\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_val /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Home\\Anaconda3\\envs\\SIP\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\Home\\Anaconda3\\envs\\SIP\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "batch_size = 256\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "\n",
    "#input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 kernel_initializer='he_normal',\n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 3, 3, 128)         73856     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               147584    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 241,546\n",
      "Trainable params: 241,546\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Home\\Anaconda3\\envs\\SIP\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/50\n",
      "48000/48000 [==============================] - 44s 917us/step - loss: 0.8395 - acc: 0.6882 - val_loss: 0.5159 - val_acc: 0.8082\n",
      "Epoch 2/50\n",
      "48000/48000 [==============================] - 44s 913us/step - loss: 0.5287 - acc: 0.8029 - val_loss: 0.4343 - val_acc: 0.8426\n",
      "Epoch 3/50\n",
      "48000/48000 [==============================] - 43s 898us/step - loss: 0.4574 - acc: 0.8301 - val_loss: 0.3911 - val_acc: 0.8589\n",
      "Epoch 4/50\n",
      "48000/48000 [==============================] - 44s 925us/step - loss: 0.4197 - acc: 0.8472 - val_loss: 0.3458 - val_acc: 0.8742\n",
      "Epoch 5/50\n",
      "48000/48000 [==============================] - 43s 898us/step - loss: 0.3850 - acc: 0.8591 - val_loss: 0.3291 - val_acc: 0.8801\n",
      "Epoch 6/50\n",
      "48000/48000 [==============================] - 43s 897us/step - loss: 0.3619 - acc: 0.8683 - val_loss: 0.3158 - val_acc: 0.8856\n",
      "Epoch 7/50\n",
      "48000/48000 [==============================] - 43s 898us/step - loss: 0.3508 - acc: 0.8697 - val_loss: 0.2988 - val_acc: 0.8901\n",
      "Epoch 8/50\n",
      "48000/48000 [==============================] - 43s 895us/step - loss: 0.3322 - acc: 0.8798 - val_loss: 0.2890 - val_acc: 0.8929\n",
      "Epoch 9/50\n",
      "48000/48000 [==============================] - 43s 904us/step - loss: 0.3149 - acc: 0.8851 - val_loss: 0.2900 - val_acc: 0.8908\n",
      "Epoch 10/50\n",
      "48000/48000 [==============================] - 44s 912us/step - loss: 0.3103 - acc: 0.8853 - val_loss: 0.2713 - val_acc: 0.8992\n",
      "Epoch 11/50\n",
      "48000/48000 [==============================] - 44s 908us/step - loss: 0.2954 - acc: 0.8922 - val_loss: 0.2648 - val_acc: 0.9022\n",
      "Epoch 12/50\n",
      "48000/48000 [==============================] - 627s 13ms/step - loss: 0.2906 - acc: 0.8916 - val_loss: 0.2561 - val_acc: 0.9041\n",
      "Epoch 13/50\n",
      "48000/48000 [==============================] - 42s 871us/step - loss: 0.2824 - acc: 0.8957 - val_loss: 0.2526 - val_acc: 0.9053\n",
      "Epoch 14/50\n",
      "48000/48000 [==============================] - 42s 867us/step - loss: 0.2780 - acc: 0.8970 - val_loss: 0.2564 - val_acc: 0.9038\n",
      "Epoch 15/50\n",
      "48000/48000 [==============================] - 42s 877us/step - loss: 0.2665 - acc: 0.9022 - val_loss: 0.2459 - val_acc: 0.9100\n",
      "Epoch 16/50\n",
      "48000/48000 [==============================] - 43s 893us/step - loss: 0.2680 - acc: 0.9005 - val_loss: 0.2471 - val_acc: 0.9076\n",
      "Epoch 17/50\n",
      "48000/48000 [==============================] - 43s 901us/step - loss: 0.2588 - acc: 0.9045 - val_loss: 0.2423 - val_acc: 0.9110\n",
      "Epoch 18/50\n",
      "48000/48000 [==============================] - 43s 901us/step - loss: 0.2558 - acc: 0.9054 - val_loss: 0.2413 - val_acc: 0.9093\n",
      "Epoch 19/50\n",
      "48000/48000 [==============================] - 44s 907us/step - loss: 0.2529 - acc: 0.9074 - val_loss: 0.2331 - val_acc: 0.9130\n",
      "Epoch 20/50\n",
      "48000/48000 [==============================] - 43s 901us/step - loss: 0.2490 - acc: 0.9073 - val_loss: 0.2313 - val_acc: 0.9139\n",
      "Epoch 21/50\n",
      "48000/48000 [==============================] - 43s 897us/step - loss: 0.2432 - acc: 0.9094 - val_loss: 0.2377 - val_acc: 0.9118\n",
      "Epoch 22/50\n",
      "48000/48000 [==============================] - 43s 890us/step - loss: 0.2416 - acc: 0.9099 - val_loss: 0.2320 - val_acc: 0.9133\n",
      "Epoch 23/50\n",
      "48000/48000 [==============================] - 43s 899us/step - loss: 0.2367 - acc: 0.9119 - val_loss: 0.2378 - val_acc: 0.9131\n",
      "Epoch 24/50\n",
      "48000/48000 [==============================] - 45s 932us/step - loss: 0.2341 - acc: 0.9122 - val_loss: 0.2261 - val_acc: 0.9156\n",
      "Epoch 25/50\n",
      "48000/48000 [==============================] - 45s 932us/step - loss: 0.2342 - acc: 0.9117 - val_loss: 0.2271 - val_acc: 0.9148\n",
      "Epoch 26/50\n",
      "48000/48000 [==============================] - 46s 961us/step - loss: 0.2253 - acc: 0.9136 - val_loss: 0.2297 - val_acc: 0.9139\n",
      "Epoch 27/50\n",
      "48000/48000 [==============================] - 44s 922us/step - loss: 0.2246 - acc: 0.9159 - val_loss: 0.2289 - val_acc: 0.9142\n",
      "Epoch 28/50\n",
      "48000/48000 [==============================] - 45s 930us/step - loss: 0.2261 - acc: 0.9151 - val_loss: 0.2215 - val_acc: 0.9176\n",
      "Epoch 29/50\n",
      "48000/48000 [==============================] - 45s 929us/step - loss: 0.2194 - acc: 0.9180 - val_loss: 0.2263 - val_acc: 0.9145\n",
      "Epoch 30/50\n",
      "48000/48000 [==============================] - 44s 927us/step - loss: 0.2212 - acc: 0.9164 - val_loss: 0.2265 - val_acc: 0.9138\n",
      "Epoch 31/50\n",
      "48000/48000 [==============================] - 44s 912us/step - loss: 0.2168 - acc: 0.9193 - val_loss: 0.2188 - val_acc: 0.9177\n",
      "Epoch 32/50\n",
      "48000/48000 [==============================] - 44s 917us/step - loss: 0.2130 - acc: 0.9197 - val_loss: 0.2258 - val_acc: 0.9169\n",
      "Epoch 33/50\n",
      "48000/48000 [==============================] - 45s 938us/step - loss: 0.2150 - acc: 0.9191 - val_loss: 0.2184 - val_acc: 0.9191\n",
      "Epoch 34/50\n",
      "48000/48000 [==============================] - 45s 933us/step - loss: 0.2084 - acc: 0.9215 - val_loss: 0.2220 - val_acc: 0.9173\n",
      "Epoch 35/50\n",
      "48000/48000 [==============================] - 45s 929us/step - loss: 0.2097 - acc: 0.9221 - val_loss: 0.2220 - val_acc: 0.9158\n",
      "Epoch 36/50\n",
      "48000/48000 [==============================] - 45s 928us/step - loss: 0.2094 - acc: 0.9218 - val_loss: 0.2181 - val_acc: 0.9192\n",
      "Epoch 37/50\n",
      "48000/48000 [==============================] - 44s 925us/step - loss: 0.2048 - acc: 0.9225 - val_loss: 0.2158 - val_acc: 0.9220\n",
      "Epoch 38/50\n",
      "48000/48000 [==============================] - 45s 932us/step - loss: 0.2023 - acc: 0.9251 - val_loss: 0.2207 - val_acc: 0.9181\n",
      "Epoch 39/50\n",
      "48000/48000 [==============================] - 44s 927us/step - loss: 0.2008 - acc: 0.9257 - val_loss: 0.2159 - val_acc: 0.9222\n",
      "Epoch 40/50\n",
      "48000/48000 [==============================] - 45s 929us/step - loss: 0.2010 - acc: 0.9240 - val_loss: 0.2153 - val_acc: 0.9199\n",
      "Epoch 41/50\n",
      "48000/48000 [==============================] - 45s 943us/step - loss: 0.1994 - acc: 0.9251 - val_loss: 0.2183 - val_acc: 0.9198\n",
      "Epoch 42/50\n",
      "48000/48000 [==============================] - 44s 922us/step - loss: 0.1987 - acc: 0.9246 - val_loss: 0.2122 - val_acc: 0.9228\n",
      "Epoch 43/50\n",
      "48000/48000 [==============================] - 44s 922us/step - loss: 0.1947 - acc: 0.9263 - val_loss: 0.2209 - val_acc: 0.9171\n",
      "Epoch 44/50\n",
      "48000/48000 [==============================] - 46s 955us/step - loss: 0.1933 - acc: 0.9271 - val_loss: 0.2139 - val_acc: 0.9214\n",
      "Epoch 45/50\n",
      "48000/48000 [==============================] - 44s 915us/step - loss: 0.1912 - acc: 0.9269 - val_loss: 0.2201 - val_acc: 0.9203\n",
      "Epoch 46/50\n",
      "48000/48000 [==============================] - 43s 889us/step - loss: 0.1899 - acc: 0.9284 - val_loss: 0.2133 - val_acc: 0.9207\n",
      "Epoch 47/50\n",
      "48000/48000 [==============================] - 44s 922us/step - loss: 0.1940 - acc: 0.9267 - val_loss: 0.2166 - val_acc: 0.9202\n",
      "Epoch 48/50\n",
      "48000/48000 [==============================] - 46s 957us/step - loss: 0.1897 - acc: 0.9291 - val_loss: 0.2129 - val_acc: 0.9222\n",
      "Epoch 49/50\n",
      "48000/48000 [==============================] - 43s 886us/step - loss: 0.1861 - acc: 0.9299 - val_loss: 0.2155 - val_acc: 0.9222\n",
      "Epoch 50/50\n",
      "48000/48000 [==============================] - 42s 883us/step - loss: 0.1846 - acc: 0.9300 - val_loss: 0.2157 - val_acc: 0.9219\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_val, y_val))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.20346736954152583\n",
      "Test accuracy: 0.9274\n"
     ]
    }
   ],
   "source": [
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
